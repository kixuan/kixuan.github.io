<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Python爬虫-3.基本库的使用【未学完...】 | 炫仔的Blog</title><meta name="author" content="Xuan"><meta name="copyright" content="Xuan"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="基本库的使用使用 urllib首先，了解一下 urllib 库，它是 Python 内置的 HTTP 请求库，也就是说不需要额外安装即可使用。它包含如下 4 个模块。  request：它是最基本的 HTTP 请求模块，可以用来模拟发送请求。就像在浏览器里输入网址然后回车一样，只需要给库方法传入 URL 以及额外的参数，就可以模拟实现这个过程了。 error：异常处理模块，如果出现请求错误，我们可">
<meta property="og:type" content="article">
<meta property="og:title" content="Python爬虫-3.基本库的使用【未学完...】">
<meta property="og:url" content="http://example.com/2023/06/10/3-%E5%9F%BA%E6%9C%AC%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/index.html">
<meta property="og:site_name" content="炫仔的Blog">
<meta property="og:description" content="基本库的使用使用 urllib首先，了解一下 urllib 库，它是 Python 内置的 HTTP 请求库，也就是说不需要额外安装即可使用。它包含如下 4 个模块。  request：它是最基本的 HTTP 请求模块，可以用来模拟发送请求。就像在浏览器里输入网址然后回车一样，只需要给库方法传入 URL 以及额外的参数，就可以模拟实现这个过程了。 error：异常处理模块，如果出现请求错误，我们可">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/avatar.png">
<meta property="article:published_time" content="2023-06-09T16:00:00.000Z">
<meta property="article:modified_time" content="2023-06-10T13:30:27.208Z">
<meta property="article:author" content="Xuan">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/avatar.png"><link rel="shortcut icon" href="/img/avatar.png"><link rel="canonical" href="http://example.com/2023/06/10/3-%E5%9F%BA%E6%9C%AC%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":"ture","top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Python爬虫-3.基本库的使用【未学完...】',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-06-10 21:30:27'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/background.css"><meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/主页背景图.jpg" data-original="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">12</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-bookmark"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/artitalk"><i class="fa-fw fa fa-comments-o"></i><span> talksome</span></a></li><li><a class="site-page child" href="/share/"><i class="fa-fw fa fa-share-alt-square"></i><span> 分享</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fa fa-images"></i><span> 图库</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fa fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://travellings.cn"><i class="fa-fw fa fa-train"></i><span> 开往</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> 关于我</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background: D:/Blog/source/_posts/img/springday"><nav id="nav"><span id="blog-info"><a href="/" title="炫仔的Blog"><span class="site-name">炫仔的Blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-bookmark"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/artitalk"><i class="fa-fw fa fa-comments-o"></i><span> talksome</span></a></li><li><a class="site-page child" href="/share/"><i class="fa-fw fa fa-share-alt-square"></i><span> 分享</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fa fa-images"></i><span> 图库</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fa fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://travellings.cn"><i class="fa-fw fa fa-train"></i><span> 开往</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> 关于我</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Python爬虫-3.基本库的使用【未学完...】</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-06-09T16:00:00.000Z" title="发表于 2023-06-10 00:00:00">2023-06-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-06-10T13:30:27.208Z" title="更新于 2023-06-10 21:30:27">2023-06-10</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>15分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Python爬虫-3.基本库的使用【未学完...】"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="基本库的使用"><a href="#基本库的使用" class="headerlink" title="基本库的使用"></a>基本库的使用</h1><h2 id="使用-urllib"><a href="#使用-urllib" class="headerlink" title="使用 urllib"></a>使用 urllib</h2><p>首先，了解一下 urllib 库，它是 Python 内置的 HTTP 请求库，也就是说不需要额外安装即可使用。它包含如下 4 个模块。</p>
<ul>
<li>request：它是最基本的 HTTP 请求模块，可以用来模拟发送请求。就像在浏览器里输入网址然后回车一样，只需要给库方法传入 URL 以及额外的参数，就可以模拟实现这个过程了。</li>
<li>error：异常处理模块，如果出现请求错误，我们可以捕获这些异常，然后进行重试或其他操作以保证程序不会意外终止。</li>
<li>parse：一个工具模块，提供了许多 URL 处理方法，比如拆分、解析、合并等。</li>
<li>robotparser：主要是用来识别网站的 robots.txt 文件，然后判断哪些网站可以爬，哪些网站不可以爬，它其实用得比较少。</li>
</ul>
<h3 id="发送请求"><a href="#发送请求" class="headerlink" title="发送请求"></a>发送请求</h3><h4 id="urlopen"><a href="#urlopen" class="headerlink" title="urlopen"></a>urlopen</h4><ul>
<li><p>构造方法</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">urllib.request.urlopen(url, data=<span class="literal">None</span>, [timeout,]-, cafile=<span class="literal">None</span>, capath=<span class="literal">None</span>, cadefault=<span class="literal">False</span>, context=<span class="literal">None</span>)</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>基本使用</p>
  <figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(<span class="string">'https://www.python.org'</span>)</span><br><span class="line"><span class="comment"># 获取返回类型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(response))</span><br><span class="line"><span class="comment"># 获取返回结果的状态码</span></span><br><span class="line"><span class="built_in">print</span>(response.status)</span><br><span class="line"><span class="comment"># 获取响应头的各数据</span></span><br><span class="line"><span class="built_in">print</span>(response.getheaders())</span><br><span class="line"><span class="comment"># 获取了响应头中的 Server 值，结果是 nginx，意思是服务器是用 Nginx 搭建的。</span></span><br><span class="line"><span class="built_in">print</span>(response.getheader(<span class="string">'Server'</span>))</span><br><span class="line"><span class="comment">#获取读取信息，即网页的源代码</span></span><br><span class="line"><span class="built_in">print</span>(response.read().decode(<span class="string">'utf-8'</span>))</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>data参数<br>将参数转化为字节流编码格式的内容，即 bytes 类型，POST请求方式</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.parse  </span><br><span class="line"><span class="keyword">import</span> urllib.request  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取hello！xxz，会传送到运行结果的word --POST模拟表单获取</span></span><br><span class="line"><span class="comment">#  urlencode 方法来将参数字典转化为字符串</span></span><br><span class="line">data = <span class="built_in">bytes</span>(urllib.parse.urlencode({<span class="string">'word'</span>: <span class="string">'hello'</span>}), encoding=<span class="string">'utf8'</span>)  </span><br><span class="line">response = urllib.request.urlopen(<span class="string">'http://httpbin.org/post'</span>, data=data)  </span><br><span class="line"><span class="built_in">print</span>(response.read())</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>timeout参数</p>
<p>  用于设置超时时间，单位为秒；如果请求超出了设置的这个时间，还没有得到响应，就会抛出异常  </p>
<blockquote>
<p>可以通过设置这个超时时间来控制一个网页如果长时间未响应，就跳过它的抓取</p>
</blockquote>
  <figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> socket  </span><br><span class="line"><span class="keyword">import</span> urllib.request  </span><br><span class="line"><span class="keyword">import</span> urllib.error  </span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:  </span><br><span class="line">    response = urllib.request.urlopen(<span class="string">'http://httpbin.org/get'</span>, timeout=<span class="number">0.1</span>)  </span><br><span class="line"><span class="keyword">except</span> urllib.error.URLError <span class="keyword">as</span> e:  </span><br><span class="line">    <span class="comment"># socket.timeout --超时异常</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(e.reason, socket.timeout):  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">'TIME OUT'</span>)</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>其他参数</p>
<p>context 参数，它必须是 ssl.SSLContext 类型，用来指定 SSL 设置</p>
<p>……</p>
<p>详见文档：<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/urllib.request.html">urllib.request — 用于打开 URL 的可扩展库 — Python 3.11.4 文档</a></p>
</li>
</ul>
<h4 id="Requset-power"><a href="#Requset-power" class="headerlink" title="Requset[power!]"></a>Requset[power!]</h4><p>如果请求中需要加入 Headers 等信息，就可以利用更强大的 Request 类来构建</p>
<ul>
<li><p>Request构造方法</p>
  <figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">urllib</span>.request.Request(url, data=<span class="literal">None</span>, headers={}, origin_req_host=<span class="literal">None</span>, unverifiable=<span class="literal">False</span>, method=<span class="literal">None</span>)</span><br></pre></td></tr></tbody></table></figure>
<ul>
<li><p>url 用于请求 URL，这是必传参数，其他都是可选参数。</p>
</li>
<li><p>data 如果要传，必须传 bytes（字节流）类型的。如果它是字典，可以先用 urllib.parse 模块里的 urlencode() 编码。</p>
</li>
<li><p>headers 是一个字典，它就是请求头，我们可以在构造请求时通过 headers 参数直接构造，也可以通过调用请求实例的 add_header() 方法添加。</p>
</li>
<li><p>unverifiable 表示这个请求是否是无法验证的，默认是 False，意思就是说用户没有足够权限来选择接收这个请求的结果。例如，我们请求一个 HTML 文档中的图片，但是我们没有自动抓取图像的权限，这时 unverifiable 的值就是 True。</p>
</li>
<li><p>method 是一个字符串，用来指示请求使用的方法，比如 GET、POST 和 PUT 等。</p>
</li>
</ul>
</li>
<li><p>初步使用</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request, parse  </span><br><span class="line"></span><br><span class="line">url = <span class="string">'http://httpbin.org/post'</span>  </span><br><span class="line">headers = {<span class="string">'User-Agent'</span>: <span class="string">'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'</span>,  </span><br><span class="line">    <span class="string">'Host'</span>: <span class="string">'httpbin.org'</span>  </span><br><span class="line">}  </span><br><span class="line"><span class="built_in">dict</span> = {<span class="string">'name'</span>: <span class="string">'Germey'</span>}  </span><br><span class="line"><span class="comment"># data用 urlencode 和 bytes 方法转成字节流</span></span><br><span class="line">data = <span class="built_in">bytes</span>(parse.urlencode(<span class="built_in">dict</span>), encoding=<span class="string">'utf8'</span>)  </span><br><span class="line">req = request.Request(url=url, data=data, headers=headers, method=<span class="string">'POST'</span>)  </span><br><span class="line"><span class="comment"># headers 也可以用 add_header 方法来添加</span></span><br><span class="line"><span class="comment"># req.add_header('User-Agent', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)')</span></span><br><span class="line">response = request.urlopen(req)  </span><br><span class="line"><span class="built_in">print</span>(response.read().decode(<span class="string">'utf-8'</span>))</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<h4 id="power"><a href="#power" class="headerlink" title="power!"></a>power!</h4><ul>
<li><p>Handler</p>
<p>把它理解为各种处理器，有专门处理登录验证的，有处理 Cookies 的，有处理代理设置的。利用它们，我们几乎可以做到 HTTP 请求中所有的事情</p>
<p>父类BaseHandler，各种子类：</p>
<ul>
<li>HTTPDefaultErrorHandler 用于处理 HTTP 响应错误，错误都会抛出 HTTPError 类型的异常。</li>
<li>HTTPRedirectHandler 用于处理重定向。</li>
<li>HTTPCookieProcessor 用于处理 Cookies。</li>
<li>ProxyHandler 用于设置代理，默认代理为空。</li>
<li>HTTPPasswordMgr 用于管理密码，它维护了用户名密码的表。</li>
<li>HTTPBasicAuthHandler 用于管理认证，如果一个链接打开时需要认证，那么可以用它来解决认证问题。</li>
<li>详情可以参考官方文档： <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/urllib.request.html#urllib.request.BaseHandler">https://docs.python.org/3/library/urllib.request.html#urllib.request.BaseHandler</a></li>
</ul>
</li>
<li><p>OpenerDirector<br>就是利用 Handler 来构建 Opener</p>
<ul>
<li><p>验证  </p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#通过代码模拟访问需要验证的页面，并获取验证后的内容</span></span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> HTTPPasswordMgrWithDefaultRealm, HTTPBasicAuthHandler, build_opener  </span><br><span class="line"><span class="keyword">from</span> urllib.error <span class="keyword">import</span> URLError  </span><br><span class="line"></span><br><span class="line">username = <span class="string">'username'</span>  </span><br><span class="line">password = <span class="string">'password'</span>  </span><br><span class="line">url = <span class="string">'http://localhost:5000/'</span>  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用add_password方法将用户名、密码和URL添加到HTTPPasswordMgrWithDefaultRealm对象中，以建立用户名和密码的映射关系。</span></span><br><span class="line">p = HTTPPasswordMgrWithDefaultRealm()  </span><br><span class="line">p.add_password(<span class="literal">None</span>, url, username, password)  </span><br><span class="line"><span class="comment"># 创建HTTPBasicAuthHandler对象，并将HTTPPasswordMgrWithDefaultRealm对象作为参数传入。这样就建立了一个处理验证的Handler</span></span><br><span class="line">auth_handler = HTTPBasicAuthHandler(p) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用build_opener方法，Opener对象在发送请求时会自动携带验证信息</span></span><br><span class="line">opener = build_opener(auth_handler)  </span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:  </span><br><span class="line">    <span class="comment"># 通过Opener对象的open方法打开指定的URL，完成验证过程。获取到验证后的页面源码内容</span></span><br><span class="line">    result = opener.<span class="built_in">open</span>(url)  </span><br><span class="line">    html = result.read().decode(<span class="string">'utf-8'</span>)  </span><br><span class="line">    <span class="built_in">print</span>(html)  </span><br><span class="line"><span class="keyword">except</span> URLError <span class="keyword">as</span> e:  </span><br><span class="line">    <span class="built_in">print</span>(e.reason)</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>代理</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 在爬虫中设置代理，以便在访问目标网站时使用指定的代理服务器</span></span><br><span class="line"><span class="keyword">from</span> urllib.error <span class="keyword">import</span> URLError  </span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> ProxyHandler, build_opener  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过ProxyHandler创建了一个代理处理器，将代理的信息传递给处理器</span></span><br><span class="line"><span class="comment"># 在本地搭建了一个代理，它运行在 9743 端口上。可以添加多个代理，以适应不同协议的请求</span></span><br><span class="line">proxy_handler = ProxyHandler({  </span><br><span class="line">    <span class="string">'http'</span>: <span class="string">'http://127.0.0.1:9743'</span>,  </span><br><span class="line">    <span class="string">'https'</span>: <span class="string">'https://127.0.0.1:9743'</span>  </span><br><span class="line">})  </span><br><span class="line"><span class="comment"># 用build_opener方法将代理处理器与其他可能的处理器（如身份验证处理器）一起构建成一个 Opener。</span></span><br><span class="line"><span class="comment"># opener是用于发送请求的对象</span></span><br><span class="line">opener = build_opener(proxy_handler)  </span><br><span class="line"><span class="keyword">try</span>:  </span><br><span class="line">    response = opener.<span class="built_in">open</span>(<span class="string">'https://www.baidu.com'</span>)  </span><br><span class="line">    <span class="built_in">print</span>(response.read().decode(<span class="string">'utf-8'</span>))  </span><br><span class="line"><span class="keyword">except</span> URLError <span class="keyword">as</span> e:  </span><br><span class="line">    <span class="built_in">print</span>(e.reason)</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>Coookies</p>
<ul>
<li>在爬虫中处理 Cookies</li>
<li>从网站获取并使用 Cookies</li>
<li>将 Cookies 保存到文件中以供后续使用</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="处理异常"><a href="#处理异常" class="headerlink" title="处理异常"></a>处理异常</h3><h4 id="URLError"><a href="#URLError" class="headerlink" title="URLError"></a>URLError</h4><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request, error  </span><br><span class="line"><span class="keyword">try</span>:  </span><br><span class="line">    response = request.urlopen(<span class="string">'https://cuiqingcai.com/index.htm'</span>)  </span><br><span class="line"><span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:  </span><br><span class="line">    <span class="built_in">print</span>(e.reason)</span><br></pre></td></tr></tbody></table></figure>

<p>打开一个不存在的页面，照理来说应该会报错，但是这时我们捕获了 URLError 这个异常，运行结果如下：</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">Not Found</span><br></pre></td></tr></tbody></table></figure>

<p>程序没有直接报错，而是输出了如上内容，这样通过如上操作，我们就可以避免程序异常终止，同时异常得到了有效处理。</p>
<h4 id="HTTPError"><a href="#HTTPError" class="headerlink" title="HTTPError"></a>HTTPError</h4><p> URLError 的子类，专门用来处理 HTTP 请求错误，比如认证请求失败等。它有如下 3 个属性。</p>
<ul>
<li><p>code：返回 HTTP 状态码，比如 404 表示网页不存在，500 表示服务器内部错误等</p>
</li>
<li><p>reason：同父类一样，用于返回错误的原因</p>
</li>
<li><p>headers：返回请求头</p>
</li>
</ul>
<p>示例：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request,error  </span><br><span class="line"><span class="keyword">try</span>:  </span><br><span class="line">    response = request.urlopen(<span class="string">'https://cuiqingcai.com/index.htm'</span>)  </span><br><span class="line"><span class="keyword">except</span> error.HTTPError <span class="keyword">as</span> e:  </span><br><span class="line">    <span class="built_in">print</span>(e.reason, e.code, e.headers, sep=<span class="string">'\n'</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>运行结果：</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">Not Found</span><br><span class="line">404</span><br><span class="line">Server: nginx/1.4.6 (Ubuntu)</span><br><span class="line">Date: Wed, 03 Aug 2016 08:54:22 GMT</span><br><span class="line">Content-Type: text/html; charset=UTF-8</span><br><span class="line">Transfer-Encoding: chunked</span><br><span class="line">Connection: close</span><br><span class="line">X-Powered-By: PHP/5.5.9-1ubuntu4.14</span><br><span class="line">Vary: Cookie</span><br><span class="line">Expires: Wed, 11 Jan 1984 05:00:00 GMT</span><br><span class="line">Cache-Control: no-cache, must-revalidate, max-age=0</span><br><span class="line">Pragma: no-cache</span><br><span class="line">Link: &lt;https://cuiqingcai.com/wp-json/&gt;; rel="https://api.w.org/"</span><br></pre></td></tr></tbody></table></figure>

<h4 id="结合使用"><a href="#结合使用" class="headerlink" title="结合使用"></a>结合使用</h4><p>因为 URLError 是 HTTPError 的父类，所以可以先选择捕获子类的错误，再去捕获父类的错误</p>
<p>先捕获 HTTPError，获取它的错误状态码、原因、headers 等信息。如果不是 HTTPError 异常，就会捕获 URLError 异常，输出错误原因。最后，用 else 来处理正常的逻辑。这是一个较好的异常处理写法。</p>
<p>reason返回字符串</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request, error  </span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:  </span><br><span class="line">    response = request.urlopen(<span class="string">'https://cuiqingcai.com/index.htm'</span>)  </span><br><span class="line"><span class="keyword">except</span> error.HTTPError <span class="keyword">as</span> e:  </span><br><span class="line">    <span class="built_in">print</span>(e.reason, e.code, e.headers, sep=<span class="string">'\n'</span>)  </span><br><span class="line"><span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:  </span><br><span class="line">    <span class="built_in">print</span>(e.reason)  </span><br><span class="line"><span class="keyword">else</span>:  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'Request Successfully'</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>reason返回对象</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> socket  </span><br><span class="line"><span class="keyword">import</span> urllib.request  </span><br><span class="line"><span class="keyword">import</span> urllib.error  </span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:  </span><br><span class="line">    response = urllib.request.urlopen(<span class="string">'https://www.baidu.com'</span>, timeout=<span class="number">0.01</span>)  </span><br><span class="line"><span class="keyword">except</span> urllib.error.URLError <span class="keyword">as</span> e:  </span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">type</span>(e.reason))  </span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(e.reason, socket.timeout):  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">'TIME OUT'</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>运行结果如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">&lt;<span class="keyword">class</span><span class="string">'socket.timeout'</span>&gt;</span><br><span class="line"><span class="comment"># reason 属性的结果是 socket.timeout 类，可以用 isinstance 方法来判断它的类型，作出更详细的异常判断。</span></span><br><span class="line">TIME OUT</span><br></pre></td></tr></tbody></table></figure>

<h3 id="解析链接"><a href="#解析链接" class="headerlink" title="解析链接"></a>解析链接</h3><h4 id="urlparse-解析URL"><a href="#urlparse-解析URL" class="headerlink" title="urlparse  -解析URL"></a>urlparse  -解析URL</h4><ul>
<li><p>构造方法</p>
  <figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">urllib.parse.urlparse(urlstring, scheme=<span class="string">''</span>, allow_fragments=<span class="literal">True</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>  3 个参数：</p>
<ul>
<li><p>urlstring：这是必填项，即待解析的 URL。</p>
</li>
<li><p>scheme：它是默认的协议（比如 http 或 https 等）。假如这个链接没有带协议信息，会将这个作为默认的协议。</p>
<blockquote>
<p>scheme 参数只有在 URL 中不包含 scheme 信息时才生效。如果 URL 中有 scheme 信息，就会返回解析出的 scheme</p>
</blockquote>
</li>
<li><p>allow_fragments：即是否忽略 fragment。如果它被设置为 False，fragment 部分就会被忽略，它会被解析为 path、parameters 或者 query 的一部分，而 fragment 部分为空。</p>
</li>
</ul>
</li>
<li><p>实现 URL 的识别和分段</p>
  <figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlparse  </span><br><span class="line"></span><br><span class="line">result = urlparse(<span class="string">'http://www.baidu.com/index.html;user?id=5#comment'</span>, scheme=<span class="string">'https'</span>, allow_fragments=<span class="literal">False</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(result), result)</span><br></pre></td></tr></tbody></table></figure>

<p>  运行结果如下：</p>
  <figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">&lt;<span class="keyword">class</span> <span class="string">'urllib.parse.ParseResult'</span>&gt;</span><br><span class="line">ParseResult(scheme=<span class="string">'http'</span>, netloc=<span class="string">'www.baidu.com'</span>, path=<span class="string">'/index.html'</span>, params=<span class="string">'user'</span>, query=<span class="string">'id=5#comment'</span>,</span><br><span class="line">fragment=<span class="string">''</span>)</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>返回结果是一个 ParseResult 类型的对象，<br>  它包含 6 个部分，分别是 scheme、netloc、path、params、query 和 fragment。可以得出一个标准的链接格式，具体如下： <code>scheme://netloc/path;params?query#fragment</code></p>
</li>
<li><p>返回结果 ParseResult 实际上是一个元组<br>  我们可以用索引顺序来获取，也可以用属性名获取。示例如下：</p>
  <figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlparse  </span><br><span class="line">  </span><br><span class="line">result = urlparse(<span class="string">'http://www.baidu.com/index.html#comment'</span>, allow_fragments=<span class="literal">False</span>)  </span><br><span class="line"><span class="built_in">print</span>(result.scheme, result[<span class="number">0</span>], result.netloc, result[<span class="number">1</span>], sep=<span class="string">'\n'</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>  分别用索引和属性名获取了 scheme 和 netloc，其运行结果如下：</p>
  <figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">http  </span><br><span class="line">http  </span><br><span class="line">www.baidu.com  </span><br><span class="line">www.baidu.com</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<h4 id="urlunparse-构造URL"><a href="#urlunparse-构造URL" class="headerlink" title="urlunparse  -构造URL"></a>urlunparse  -构造URL</h4><p>有了 urlparse 方法，相应地就有了它的对立方法 urlunparse。它接受的参数是一个可迭代对象，但是它的长度必须是 6，否则会抛出参数数量不足或者过多的问题。先用一个实例看一下：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlunparse  </span><br><span class="line"></span><br><span class="line">data = [<span class="string">'http'</span>, <span class="string">'www.baidu.com'</span>, <span class="string">'index.html'</span>, <span class="string">'user'</span>, <span class="string">'a=6'</span>, <span class="string">'comment'</span>]  </span><br><span class="line"><span class="built_in">print</span>(urlunparse(data))</span><br></pre></td></tr></tbody></table></figure>

<p>这里参数 data 用了列表类型。也可以用其他类型，比如元组或者特定的数据结构。运行结果如下： </p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">http://www.baidu.com/index.html;user?a=6#comment</span><br></pre></td></tr></tbody></table></figure>

<h4 id="urlsplit-解析URL"><a href="#urlsplit-解析URL" class="headerlink" title="urlsplit  -解析URL"></a>urlsplit  -解析URL</h4><p>它不再单独解析 params 这一部分，只返回 5 个结果， params 会合并到 path 中</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlsplit  </span><br><span class="line">result = urlsplit(<span class="string">'http://www.baidu.com/index.html;user?id=5#comment'</span>)  </span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></tbody></table></figure>

<p>运行结果如下：  </p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">SplitResult(scheme=<span class="string">'http'</span>, netloc=<span class="string">'www.baidu.com'</span>, path=<span class="string">'/index.html;user'</span>, query=<span class="string">'id=5'</span>, fragment=<span class="string">'comment'</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>返回结果是 SplitResult，也是一个元组类型，既可以用属性获取值，也可以用索引来获取</p>
<h4 id="urlunsplit-构造URL"><a href="#urlunsplit-构造URL" class="headerlink" title="urlunsplit  -构造URL"></a>urlunsplit  -构造URL</h4><p>与 urlunparse 方法类似，它也是将链接各个部分组合成完整链接的方法，传入的参数也是一个可迭代对象，例如列表、元组等，唯一的区别是长度必须为 5。</p>
<p>示例如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlunsplit  </span><br><span class="line"></span><br><span class="line">data = [<span class="string">'http'</span>, <span class="string">'www.baidu.com'</span>, <span class="string">'index.html'</span>, <span class="string">'a=6'</span>, <span class="string">'comment'</span>]  </span><br><span class="line"><span class="built_in">print</span>(urlunsplit(data))</span><br></pre></td></tr></tbody></table></figure>

<p>运行结果如下： </p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">http://www.baidu.com/index.html?a=6#comment</span><br></pre></td></tr></tbody></table></figure>

<h4 id="urljoin-解析URL"><a href="#urljoin-解析URL" class="headerlink" title="urljoin -解析URL"></a>urljoin -解析URL</h4><p>提供一个 base_url（基础链接）作为第一个参数，将新的链接作为第二个参数，该方法会分析 base_url 的 scheme、netloc 和 path 这 3 个内容并对新链接缺失的部分进行补充，最后返回结果。</p>
<p>示例：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urljoin  </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(urljoin(<span class="string">'http://www.baidu.com'</span>, <span class="string">'FAQ.html'</span>))  </span><br><span class="line"><span class="built_in">print</span>(urljoin(<span class="string">'http://www.baidu.com'</span>, <span class="string">'https://cuiqingcai.com/FAQ.html'</span>))  </span><br><span class="line"><span class="built_in">print</span>(urljoin(<span class="string">'http://www.baidu.com/about.html'</span>, <span class="string">'https://cuiqingcai.com/FAQ.html'</span>))  </span><br><span class="line"><span class="built_in">print</span>(urljoin(<span class="string">'http://www.baidu.com/about.html'</span>, <span class="string">'https://cuiqingcai.com/FAQ.html?question=2'</span>))  </span><br><span class="line"><span class="built_in">print</span>(urljoin(<span class="string">'http://www.baidu.com?wd=abc'</span>, <span class="string">'https://cuiqingcai.com/index.php'</span>))  </span><br><span class="line"><span class="built_in">print</span>(urljoin(<span class="string">'http://www.baidu.com'</span>, <span class="string">'?category=2#comment'</span>))  </span><br><span class="line"><span class="built_in">print</span>(urljoin(<span class="string">'www.baidu.com'</span>, <span class="string">'?category=2#comment'</span>))  </span><br><span class="line"><span class="built_in">print</span>(urljoin(<span class="string">'www.baidu.com#comment'</span>, <span class="string">'?category=2'</span>))</span><br></pre></td></tr></tbody></table></figure>

<p>运行结果：</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">http://www.baidu.com/FAQ.html  </span><br><span class="line">https://cuiqingcai.com/FAQ.html  </span><br><span class="line">https://cuiqingcai.com/FAQ.html  </span><br><span class="line">https://cuiqingcai.com/FAQ.html?question=2  </span><br><span class="line">https://cuiqingcai.com/index.php  </span><br><span class="line">http://www.baidu.com?category=2#comment  </span><br><span class="line">www.baidu.com?category=2#comment  </span><br><span class="line">www.baidu.com?category=2</span><br></pre></td></tr></tbody></table></figure>

<h4 id="urlencode-转GET请求参数"><a href="#urlencode-转GET请求参数" class="headerlink" title="urlencode  -转GET请求参数"></a>urlencode  -转GET请求参数</h4><p>示例：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode  </span><br><span class="line"></span><br><span class="line">params = {  </span><br><span class="line">    <span class="string">'name'</span>: <span class="string">'germey'</span>,  </span><br><span class="line">    <span class="string">'age'</span>: <span class="number">22</span>  </span><br><span class="line">}  </span><br><span class="line">base_url = <span class="string">'http://www.baidu.com?'</span>  </span><br><span class="line">url = base_url + urlencode(params)  </span><br><span class="line"><span class="built_in">print</span>(url)</span><br></pre></td></tr></tbody></table></figure>

<p>这里首先声明了一个字典来将参数表示出来，然后调用 urlencode 方法将其序列化为 GET 请求参数。运行结果如下：</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">http://www.baidu.com?name=germey&amp;amp;age=22</span><br></pre></td></tr></tbody></table></figure>

<p>这个方法非常常用。有时为了更加方便地构造参数，我们会事先用字典来表示。要转化为 URL 的参数时，只需要调用该方法即可。</p>
<h4 id="parse-qs-转字典"><a href="#parse-qs-转字典" class="headerlink" title="parse_qs    -转字典"></a>parse_qs    -转字典</h4><p>利用 parse_qs 方法，就可以将它转回字典，示例如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> parse_qs  </span><br><span class="line"></span><br><span class="line">query = <span class="string">'name=germey&amp;amp;age=22'</span>  </span><br><span class="line"><span class="built_in">print</span>(parse_qs(query))</span><br></pre></td></tr></tbody></table></figure>

<p>运行结果如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">{<span class="string">'name'</span>: [<span class="string">'germey'</span>], <span class="string">'age'</span>: [<span class="string">'22'</span>]}</span><br></pre></td></tr></tbody></table></figure>

<h4 id="parse-qsl-转元组"><a href="#parse-qsl-转元组" class="headerlink" title="parse_qsl   -转元组"></a>parse_qsl   -转元组</h4><p>将参数转化为元组组成的列表，示例如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> parse_qsl  </span><br><span class="line"></span><br><span class="line">query = <span class="string">'name=germey&amp;amp;age=22'</span>  </span><br><span class="line"><span class="built_in">print</span>(parse_qsl(query))</span><br></pre></td></tr></tbody></table></figure>

<p>运行结果如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">[(<span class="string">'name'</span>, <span class="string">'germey'</span>), (<span class="string">'age'</span>, <span class="string">'22'</span>)]</span><br></pre></td></tr></tbody></table></figure>

<h4 id="quote-URL-编码"><a href="#quote-URL-编码" class="headerlink" title="quote  -URL 编码"></a>quote  -URL 编码</h4><p>将内容（中文）转化为 URL 编码的格式</p>
<p>示例如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> quote  </span><br><span class="line"></span><br><span class="line">keyword = <span class="string">' 壁纸 '</span>  </span><br><span class="line">url = <span class="string">'https://www.baidu.com/s?wd='</span> + quote(keyword)  </span><br><span class="line"><span class="built_in">print</span>(url)</span><br></pre></td></tr></tbody></table></figure>

<p>这里我们声明了一个中文的搜索文字，然后用 quote 方法对其进行 URL 编码，最后得到的结果如下：</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">https://www.baidu.com/s?wd=% E5% A3%81% E7% BA% B8</span><br></pre></td></tr></tbody></table></figure>

<h4 id="unquote-–URL-解码"><a href="#unquote-–URL-解码" class="headerlink" title="unquote  –URL 解码"></a>unquote  –URL 解码</h4><p>进行 URL 解码，示例如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> unquote  </span><br><span class="line"></span><br><span class="line">url = <span class="string">'https://www.baidu.com/s?wd=% E5% A3%81% E7% BA% B8'</span>  </span><br><span class="line"><span class="built_in">print</span>(unquote(url))</span><br></pre></td></tr></tbody></table></figure>

<p>这是上面得到的 URL 编码后的结果，这里利用 unquote 方法还原，结果如下：</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">https://www.baidu.com/s?wd = 壁纸</span><br></pre></td></tr></tbody></table></figure>

<h3 id="分析Robots"><a href="#分析Robots" class="headerlink" title="分析Robots"></a>分析Robots</h3><h4 id="Robots-协议"><a href="#Robots-协议" class="headerlink" title="Robots 协议"></a>Robots 协议</h4><p>Robots 协议也称作爬虫协议，用来告诉爬虫和搜索引擎哪些页面可以抓取，哪些不可以抓取。它通常是一个叫作 robots.txt 的文本文件，一般放在网站的根目录下。</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 其设置为 * 则代表该协议对任何爬取爬虫有效</span></span><br><span class="line">User-agent: *         </span><br><span class="line"><span class="comment">#指定了不允许抓取的目录，比如上例子中设置为 / 则代表不允许抓取所有页面。</span></span><br><span class="line">Disallow: /  </span><br><span class="line"><span class="comment"># Allow一般不会单独使用，用来排除某些限制,表示只可以抓取 public 目录</span></span><br><span class="line">Allow: /public/</span><br></pre></td></tr></tbody></table></figure>

<h4 id="爬虫名称"><a href="#爬虫名称" class="headerlink" title="爬虫名称"></a>爬虫名称</h4><p>一些常见搜索爬虫的名称及其对应的网站</p>
<table>
<thead>
<tr>
<th>爬虫名称</th>
<th>名　　称</th>
<th>网　　站</th>
</tr>
</thead>
<tbody><tr>
<td>BaiduSpider</td>
<td>百度</td>
<td><a target="_blank" rel="noopener" href="http://www.baidu.com/">www.baidu.com</a></td>
</tr>
<tr>
<td>Googlebot</td>
<td>谷歌</td>
<td><a target="_blank" rel="noopener" href="http://www.google.com/">www.google.com</a></td>
</tr>
<tr>
<td>360Spider</td>
<td>360 搜索</td>
<td><a target="_blank" rel="noopener" href="http://www.so.com/">www.so.com</a></td>
</tr>
<tr>
<td>YodaoBot</td>
<td>有道</td>
<td><a target="_blank" rel="noopener" href="http://www.youdao.com/">www.youdao.com</a></td>
</tr>
<tr>
<td>ia_archiver</td>
<td>Alexa</td>
<td><a target="_blank" rel="noopener" href="http://www.alexa.cn/">www.alexa.cn</a></td>
</tr>
<tr>
<td>Scooter</td>
<td>altavista</td>
<td><a target="_blank" rel="noopener" href="http://www.altavista.com/">www.altavista.com</a></td>
</tr>
</tbody></table>
<h4 id="robotparser"><a href="#robotparser" class="headerlink" title="robotparser"></a>robotparser</h4><p>使用 robotparser 模块来解析 robots.txt</p>
<ul>
<li><p>构造方法  (very easy啦</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">urllib.robotparser.RobotFileParser(url=<span class="string">''</span>)</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>模块常用方法</p>
<ul>
<li>set_url ：用来设置 robots.txt 文件的链接</li>
<li>read：读取 robots.txt 文件并进行分析，一般为ture</li>
<li>parse：用来解析 robots.txt 文件</li>
<li>can_fetch：该方法传入两个参数 User-agent&amp; URL。返回的内容是该搜索引擎是否可以抓取这个 URL，返回结果是 True 或 False</li>
<li>mtime：返回的是上次抓取和分析 robots.txt 的时间</li>
<li>modified：将当前时间设置为上次抓取和分析 robots.txt 的时间</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.robotparser <span class="keyword">import</span> RobotFileParser</span><br><span class="line">rp = RobotFileParser()</span><br><span class="line"><span class="comment"># rp = RobotFileParser('http://www.jianshu.com/robots.txt')</span></span><br><span class="line">rp.set_url(<span class="string">'http://www.jianshu.com/robots.txt'</span>)</span><br><span class="line">rp.read()</span><br><span class="line"><span class="comment"># 也可以使用 parse 方法执行读取和分析</span></span><br><span class="line"><span class="comment"># rp.parse(urlopen('http://www.jianshu.com/robots.txt').read().decode('utf-8').split('\n'))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用 can_fetch 方法判断了网页是否可以被抓取   True + False</span></span><br><span class="line"><span class="built_in">print</span>(rp.can_fetch(<span class="string">'*'</span>, <span class="string">'http://www.jianshu.com/p/b67554025d7d'</span>))</span><br><span class="line"><span class="built_in">print</span>(rp.can_fetch(<span class="string">'*'</span>, <span class="string">"http://www.jianshu.com/search?q=python&amp;page=1&amp;type=collections"</span>))</span><br></pre></td></tr></tbody></table></figure>

<h2 id="使用-requests"><a href="#使用-requests" class="headerlink" title="使用 requests"></a>使用 requests</h2><h3 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h3></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">Xuan</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2023/06/10/3-%E5%9F%BA%E6%9C%AC%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/">http://example.com/2023/06/10/3-%E5%9F%BA%E6%9C%AC%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">炫仔的Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/img/avatar.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/06/10/1-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" title="Python爬虫-1.开发环境配置【完善中...】"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Python爬虫-1.开发环境配置【完善中...】</div></div></a></div><div class="next-post pull-right"><a href="/2023/06/10/2-%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/" title="Python爬虫-2.爬虫基础"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Python爬虫-2.爬虫基础</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/主页背景图.jpg" data-original="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Xuan</div><div class="author-info__description">能活一天是一天</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">12</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/kixuan"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">1.</span> <span class="toc-text">基本库的使用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-urllib"><span class="toc-number">1.1.</span> <span class="toc-text">使用 urllib</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%91%E9%80%81%E8%AF%B7%E6%B1%82"><span class="toc-number">1.1.1.</span> <span class="toc-text">发送请求</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#urlopen"><span class="toc-number">1.1.1.1.</span> <span class="toc-text">urlopen</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Requset-power"><span class="toc-number">1.1.1.2.</span> <span class="toc-text">Requset[power!]</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#power"><span class="toc-number">1.1.1.3.</span> <span class="toc-text">power!</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E5%BC%82%E5%B8%B8"><span class="toc-number">1.1.2.</span> <span class="toc-text">处理异常</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#URLError"><span class="toc-number">1.1.2.1.</span> <span class="toc-text">URLError</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#HTTPError"><span class="toc-number">1.1.2.2.</span> <span class="toc-text">HTTPError</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8"><span class="toc-number">1.1.2.3.</span> <span class="toc-text">结合使用</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%9E%90%E9%93%BE%E6%8E%A5"><span class="toc-number">1.1.3.</span> <span class="toc-text">解析链接</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#urlparse-%E8%A7%A3%E6%9E%90URL"><span class="toc-number">1.1.3.1.</span> <span class="toc-text">urlparse  -解析URL</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#urlunparse-%E6%9E%84%E9%80%A0URL"><span class="toc-number">1.1.3.2.</span> <span class="toc-text">urlunparse  -构造URL</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#urlsplit-%E8%A7%A3%E6%9E%90URL"><span class="toc-number">1.1.3.3.</span> <span class="toc-text">urlsplit  -解析URL</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#urlunsplit-%E6%9E%84%E9%80%A0URL"><span class="toc-number">1.1.3.4.</span> <span class="toc-text">urlunsplit  -构造URL</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#urljoin-%E8%A7%A3%E6%9E%90URL"><span class="toc-number">1.1.3.5.</span> <span class="toc-text">urljoin -解析URL</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#urlencode-%E8%BD%ACGET%E8%AF%B7%E6%B1%82%E5%8F%82%E6%95%B0"><span class="toc-number">1.1.3.6.</span> <span class="toc-text">urlencode  -转GET请求参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#parse-qs-%E8%BD%AC%E5%AD%97%E5%85%B8"><span class="toc-number">1.1.3.7.</span> <span class="toc-text">parse_qs    -转字典</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#parse-qsl-%E8%BD%AC%E5%85%83%E7%BB%84"><span class="toc-number">1.1.3.8.</span> <span class="toc-text">parse_qsl   -转元组</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#quote-URL-%E7%BC%96%E7%A0%81"><span class="toc-number">1.1.3.9.</span> <span class="toc-text">quote  -URL 编码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#unquote-%E2%80%93URL-%E8%A7%A3%E7%A0%81"><span class="toc-number">1.1.3.10.</span> <span class="toc-text">unquote  –URL 解码</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E6%9E%90Robots"><span class="toc-number">1.1.4.</span> <span class="toc-text">分析Robots</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Robots-%E5%8D%8F%E8%AE%AE"><span class="toc-number">1.1.4.1.</span> <span class="toc-text">Robots 协议</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%88%AC%E8%99%AB%E5%90%8D%E7%A7%B0"><span class="toc-number">1.1.4.2.</span> <span class="toc-text">爬虫名称</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#robotparser"><span class="toc-number">1.1.4.3.</span> <span class="toc-text">robotparser</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-requests"><span class="toc-number">1.2.</span> <span class="toc-text">使用 requests</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95"><span class="toc-number">1.2.1.</span> <span class="toc-text">基本用法</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/06/10/1-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" title="Python爬虫-1.开发环境配置【完善中...】">Python爬虫-1.开发环境配置【完善中...】</a><time datetime="2023-06-09T16:00:00.000Z" title="发表于 2023-06-10 00:00:00">2023-06-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/06/10/3-%E5%9F%BA%E6%9C%AC%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/" title="Python爬虫-3.基本库的使用【未学完...】">Python爬虫-3.基本库的使用【未学完...】</a><time datetime="2023-06-09T16:00:00.000Z" title="发表于 2023-06-10 00:00:00">2023-06-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/06/10/2-%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/" title="Python爬虫-2.爬虫基础">Python爬虫-2.爬虫基础</a><time datetime="2023-06-09T16:00:00.000Z" title="发表于 2023-06-10 00:00:00">2023-06-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/06/08/Maven/" title="Maven">Maven</a><time datetime="2023-06-07T16:00:00.000Z" title="发表于 2023-06-08 00:00:00">2023-06-08</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/06/08/MybatisPlus/" title="MybatisPlus">MybatisPlus</a><time datetime="2023-06-07T16:00:00.000Z" title="发表于 2023-06-08 00:00:00">2023-06-08</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 By Xuan</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><a target="_blank" href="https://wap.miit.gov.cn/" >我好像没有备号o_o ....</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async src="D:/Blog/themes/butterfly/source/js/FunnyTitle.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="true" data-text="富强,民主,文明,和谐" data-fontsize="15px" data-random="true" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 1,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(r){r.imageLazyLoadSetting.processImages=t;var e=r.imageLazyLoadSetting.isSPA,n=r.imageLazyLoadSetting.preloadRatio||1,c=a();function a(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(){e&&(c=a());for(var t,o=0;o<c.length;o++)0<=(t=(t=c[o]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(r.innerHeight*n||document.documentElement.clientHeight*n)&&function(){var t,e,n,a,i=c[o];e=function(){c=c.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(n=new Image,a=t.getAttribute("data-original"),n.onload=function(){t.src=a,t.removeAttribute("data-original"),e&&e()},t.src!==a&&(n.src=a))}()}function i(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",i),r.addEventListener("resize",i),r.addEventListener("orientationchange",i)}(this);</script></body></html>